{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "from torchvision.transforms import transforms\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "import uuid\n",
    "import cv2\n",
    "from imutils import face_utils\n",
    "import dlib\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = [(0,0,255),(255,150,40),(0,255,0),(255,128,255),(0,255,255),\n",
    "          (255,128,128),(0,128,255),(128,0,255),(255,255,128),(192,128,255),(128,255,128)]\n",
    "class FaceServiceAssigment:\n",
    "    def __init__(self, model, thresh=100, dist=100):\n",
    "        self.thresh = thresh\n",
    "        self.model = model\n",
    "        self.dist = dist\n",
    "        self.faces = []\n",
    "\n",
    "    def predict(self, img1, img2):\n",
    "        img1 = Image.fromarray(np.uint8(cm.gist_earth(img1) * 255))\n",
    "        img2 = Image.fromarray(np.uint8(cm.gist_earth(img2) * 255))\n",
    "\n",
    "        m1 = img1.convert('L')\n",
    "        m2 = img2.convert('L')\n",
    "        trans = transforms.Resize((28, 28))\n",
    "        m1 = trans(m1)\n",
    "        m2 = trans(m2)\n",
    "\n",
    "        m1 = np.array(m1)\n",
    "        m2 = np.array(m2)\n",
    "        m1 = np.expand_dims(m1, axis=0)\n",
    "        m2 = np.expand_dims(m2, axis=0)\n",
    "        pred = self.model.predict([m1, m2])\n",
    "        return pred\n",
    "\n",
    "    \n",
    "    def getRandomColor(self,i):\n",
    "        if i<len(colors):\n",
    "            return colors[i]\n",
    "        else:\n",
    "            return colors[i%10]\n",
    "\n",
    "\n",
    "    def setFacesFirstFrame(self, faces_roi):\n",
    "        for i, roi in enumerate(faces_roi):\n",
    "            self.faces.append({\"color\": self.getRandomColor(i), \"face\": roi[\"face\"], 'xyhw': roi[\"xyhw\"],\n",
    "                               'bit': 0, 'id': i, 'toDraw': True})\n",
    "\n",
    "    def drawFaces(self, frame):\n",
    "        font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "        fontScale = 1\n",
    "        thicknessText = 2\n",
    "\n",
    "        for face in self.faces:\n",
    "            if face[\"toDraw\"]:\n",
    "                x, y, h, w = face[\"xyhw\"]\n",
    "                x, y, h, w = int(x)-5, int(y)-5, int(h)+10, int(w)+10\n",
    "                center = (x + w // 2, y + h // 2)\n",
    "                frame = cv2.ellipse(frame, (center, (w//2, h//2), 0),face[\"color\"] , 2)\n",
    "                frame = cv2.putText(frame,'id:'+str(face[\"id\"]),(center[0]-30,center[1]-30), font, fontScale, \n",
    "                                    face[\"color\"], thicknessText, cv2.LINE_AA)\n",
    "        return frame\n",
    "\n",
    "\n",
    "    def reAssignFaces(self, faces_roi_to_assign, thresh=10):\n",
    "        try:                \n",
    "            number_faces_in_store = len(self.faces)\n",
    "            number_faces_assign = len(faces_roi_to_assign)\n",
    "            matrix = np.ones([number_faces_assign, number_faces_in_store])\n",
    "\n",
    "            for i, face_roi in enumerate(faces_roi_to_assign):\n",
    "                check = True\n",
    "                for j, face_item in enumerate(self.faces):\n",
    "                    matrix[i][j] = self.thresh\n",
    "                    if check:\n",
    "                        matrix[i][j] = self.predict(face_roi[\"face\"], face_item[\"face\"])\n",
    "                        if matrix[i][j] < 2:\n",
    "                            check = False\n",
    "\n",
    "            # need to find the min each row        \n",
    "            min_values_per_row = (matrix.argmin(axis=1))\n",
    "\n",
    "            ## switch faces \n",
    "            for i, face_roi in enumerate(faces_roi_to_assign):\n",
    "                if matrix[i][min_values_per_row[i]] < self.thresh:\n",
    "                    self.faces[min_values_per_row[i]][\"toDraw\"] = True\n",
    "                    x, y, h, w = self.faces[min_values_per_row[i]][\"xyhw\"]\n",
    "                    x, y, h, w = int(x), int(y), int(h), int(w)\n",
    "                    center_old = np.array([x + w // 2, y + h // 2])\n",
    "\n",
    "                    x, y, h, w = face_roi[\"xyhw\"]\n",
    "                    x, y, h, w = int(x), int(y), int(h), int(w)\n",
    "                    center_nw = np.array([x + w // 2, y + h // 2])\n",
    "\n",
    "                    dist = np.linalg.norm(center_nw - center_old)\n",
    "                    #print(dist)\n",
    "                    if dist < self.dist:\n",
    "                        self.faces[min_values_per_row[i]][\"face\"] = face_roi[\"face\"]\n",
    "                        self.faces[min_values_per_row[i]][\"xyhw\"] = face_roi[\"xyhw\"]\n",
    "                        self.faces[min_values_per_row[i]][\"toDraw\"] = True\n",
    "                        \n",
    "                else:\n",
    "#                     print(\"Score: \",min_values_per_row[i],matrix[i][min_values_per_row[i]])\n",
    "                    self.faces[min_values_per_row[i]][\"toDraw\"] = False\n",
    "                                       \n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            pass\n",
    "\n",
    "\n",
    "    def getFaces(self):\n",
    "        return self.faces\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclidean_distance(vects):\n",
    "    x, y = vects\n",
    "    sum_square = K.sum(K.square(x - y), axis=1, keepdims=True)\n",
    "    return K.sqrt(K.maximum(sum_square, K.epsilon()))\n",
    "\n",
    "\n",
    "def eucl_dist_output_shape(shapes):\n",
    "    shape1, shape2 = shapes\n",
    "    return shape1[0], 1\n",
    "\n",
    "\n",
    "def contrastive_loss(y_true, y_pred):\n",
    "    '''Contrastive loss from Hadsell-et-al.'06\n",
    "    http://yann.lecun.com/exdb/publis/pdf/hadsell-chopra-lecun-06.pdf\n",
    "    '''\n",
    "    margin = 1\n",
    "    square_pred = K.square(y_pred)\n",
    "    margin_square = K.square(K.maximum(margin - y_pred, 0))\n",
    "    return K.mean(y_true * square_pred + (1 - y_true) * margin_square)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize(**images):\n",
    "        \"\"\"PLot images in one row.\"\"\"\n",
    "        n = len(images)\n",
    "        plt.figure(figsize=(16, 5))\n",
    "        for i, (name, image) in enumerate(images.items()):\n",
    "            plt.subplot(1, n, i + 1)\n",
    "            plt.xticks([])\n",
    "            plt.yticks([])\n",
    "            plt.title(' '.join(name.split('_')).title())\n",
    "            plt.imshow(image)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras import backend as K\n",
    "from keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"siamese_network/Keras_cnn_model1592994168.1201453\"\n",
    "model = keras.models.load_model(path, custom_objects={'contrastive_loss': contrastive_loss})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_216\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_323 (InputLayer)          [(None, 28, 28)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_324 (InputLayer)          [(None, 28, 28)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "model_215 (Model)               (None, 128)          133504      input_323[0][0]                  \n",
      "                                                                 input_324[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_108 (Lambda)             (None, 1)            0           model_215[1][0]                  \n",
      "                                                                 model_215[2][0]                  \n",
      "==================================================================================================\n",
      "Total params: 133,504\n",
      "Trainable params: 133,504\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {
    "pixiedust": {
     "displayParams": {}
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def test(path, skip=0, limit=100, thresh=50, dist=100, write=False, minNeighbors=3, thresh_dnn=0.4):\n",
    "    face_service = FaceServiceAssigment(model, thresh, dist)\n",
    "    video_path = path\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    # face_cascade = cv2.CascadeClassifier('./haarcascade_frontalface_alt.xml')\n",
    "    size_w = 1920\n",
    "    size_h = 1080\n",
    "    # network\n",
    "    modelFile = \"siamese_network/content/opencv_face_detector_uint8.pb\"\n",
    "    configFile = \"siamese_network/content/opencv_face_detector.pbtxt\"\n",
    "    net = cv2.dnn.readNetFromTensorflow(modelFile, configFile)\n",
    "\n",
    "    start_frame_number = skip\n",
    "    cap.set(cv2.CAP_PROP_POS_FRAMES, start_frame_number)\n",
    "    ret, frame = cap.read()\n",
    "    frame = cv2.resize(frame, (size_w, size_h))\n",
    "\n",
    "    print(frame.shape)\n",
    "    conf_threshold = thresh_dnn\n",
    "    frameWidth = frame.shape[1]\n",
    "    frameHeight = frame.shape[0]    \n",
    "\n",
    "    if write:\n",
    "        print(\"in write mode\")\n",
    "        fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "        out = cv2.VideoWriter('output_' + str(time.time()) + '.mp4', fourcc, 20.0, (frameWidth, frameHeight))\n",
    "\n",
    "    frame_skip = skip\n",
    "    frame_index = 0\n",
    "\n",
    "    while True:\n",
    "        if frame_index % 2 == 0:\n",
    "            # Capture frame-by-frame\n",
    "            ret, frame = cap.read()\n",
    "            if ret is None or frame is None:\n",
    "                break\n",
    "            frame = cv2.resize(frame, (size_w, size_h))\n",
    "            frame = cv2.UMat(frame)\n",
    "\n",
    "            # Our operations on the frame come here\n",
    "            gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "            frame_gray = cv2.equalizeHist(gray)\n",
    "            # Detect faces           \n",
    "            blob = cv2.dnn.blobFromImage(frame, 1.0, (300, 300), [104, 117, 123], False, False)\n",
    "            net.setInput(blob)\n",
    "            detections = net.forward()\n",
    "            faces = []\n",
    "            for i in range(detections.shape[2]):\n",
    "                confidence = detections[0, 0, i, 2]\n",
    "                if confidence > conf_threshold:\n",
    "                    x1 = int(detections[0, 0, i, 3] * frameWidth)\n",
    "                    y1 = int(detections[0, 0, i, 4] * frameHeight)\n",
    "                    x2 = int(detections[0, 0, i, 5] * frameWidth)\n",
    "                    y2 = int(detections[0, 0, i, 6] * frameHeight)\n",
    "                    w = x2 - x1\n",
    "                    h = y2 - y1\n",
    "                    faces.append((x1, y1, w, h))\n",
    "\n",
    "            faces_frames = []\n",
    "            for (x, y, w, h) in faces:\n",
    "                faceROI = frame_gray.get()[y:y + h, x:x + w]\n",
    "                faces_frames.append({'face': faceROI, 'xyhw': (x, y, w, h)})\n",
    "#                 visualize(face = faceROI)\n",
    "            if frame_index == 0:\n",
    "                face_service.setFacesFirstFrame(faces_frames)\n",
    "                print(\"Detect in first frame\", len(faces_frames))\n",
    "            else:\n",
    "                if len(faces_frames) != 0:\n",
    "                    face_service.reAssignFaces(faces_frames, thresh)\n",
    "\n",
    "            frame = face_service.drawFaces(frame)\n",
    "            cv2.imshow('frame', frame)\n",
    "            \n",
    "            if write:\n",
    "                image = frame.get()\n",
    "                image = cv2.resize(image, (size_w, size_h))\n",
    "                out.write(image)\n",
    "\n",
    "            if frame_index > limit:\n",
    "                break\n",
    "\n",
    "            cv2.waitKey(10)\n",
    "\n",
    "            # Display the resulting frame\n",
    "            if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                break\n",
    "        frame_index += 1\n",
    "\n",
    "    # When everything is done, release the capture\n",
    "    cap.release()\n",
    "    \n",
    "    if write:\n",
    "        print(\"in write mode close\")\n",
    "        out.release()\n",
    "\n",
    "    cv2.destroyAllWindows()\n",
    "    \n",
    "\n",
    "    print(\"frame_index:\", frame_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path = \"siamese_network/content/Walking.mp4\"\n",
    "path = \"siamese_network/content/videoblocks.mp4\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1080, 1920, 3)\n",
      "in write mode\n",
      "Detect in first frame 9\n",
      "Score:  7 100.66983795166016\n",
      "Score:  5 132.9446258544922\n",
      "in write mode close\n",
      "frame_index: 276\n",
      "Wall time: 8min 30s\n"
     ]
    }
   ],
   "source": [
    "mins = 0\n",
    "sec = 0\n",
    "\n",
    "skip = int(60 * 29 * mins) + int(29 * sec)\n",
    "%time test(path, skip=skip, limit=275, thresh=100, dist=140, write=True, minNeighbors=3, thresh_dnn=0.164)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
